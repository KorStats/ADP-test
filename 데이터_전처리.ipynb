{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHrbUv6HYWYnitwxTqCyY9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KorStats/ADP-test/blob/main/%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%A0%84%EC%B2%98%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이상치 확인\n",
        "def outliers_iqr(dt, col):\n",
        "  quantile_1, quantile_3=np.percentile(dt[col], [25, 75])\n",
        "  iqr=quantile_3-quantile_1\n",
        "  lower_whis=quantile_1-(iqr*1.5)\n",
        "  upper_whis=quantile_3+(iqr*1.5)\n",
        "  outliers=dt[(dt[col] > upper_whis) | (dt[col] < lower_whis)]\n",
        "  return outliers[[col]]\n",
        "\n",
        "outliers=outliers_iqr(df, 'color_intensity')\n",
        "drop_outliers=df.drop(index=ouliers.index) #이상치 제거\n",
        "df['color_intensity'].fillna(df['color_intensity'].mean()) #이상치 대체\n",
        "df_dummy=pd.get_dummies(df, columns=['Class']) #범주형 변수 처리"
      ],
      "metadata": {
        "id": "tUwrYUNacY1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.medel_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.1, random_state=0, stratify='y')"
      ],
      "metadata": {
        "id": "8g9F_NpOePir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#StandardScaler : 평균이0, 분산이 1인 정규분포로 스케일링, 이상치에 매우 민감, 분류분석에 유용\n",
        "#MinMaxScaler : 0과 1사이의 값으로 스케일링, 이상치에 매우 민감, 회귀분석에 유용\n",
        "#MaxAbsScaler : -1과 1사이의 값으로 스케일링, 이상치에 매우 민감, 회귀분석에 유용\n",
        "#RobustScaler : 중앙값과 사분위값을 활용, 이상치 영향 최소화\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler\n",
        "Scaler=StandardScaler() / MinMaxScaler() / MaxAbsScaler() / RobustScaler()\n",
        "X_train_sc=scaler.fit_transform(X_train)\n",
        "X_test_sc=scaler.transform(X_test)\n",
        "X_Original=scaler.inverse_transform(X_train_sc) #원본으로 변경"
      ],
      "metadata": {
        "id": "Ye-pGvVte9sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "x=StandardScaler().fit_transform(x)\n",
        "pca=PCA(n_components=4)\n",
        "pca_fit=pca.fit(x)\n",
        "pca.singular_values_ #고유값\n",
        "pca.explained_variance_ratio_ #분산설명력\n",
        "plt.plot(pca.explained_variance_ratio_, 'o-') #Scree Plot\n",
        "plt.title('Scree Plot') / plt.xlabel('Number of Components') / plt.ylabel('Cumulative Explained Variance')\n",
        "\n",
        "pca=PCA(n_components=2) #주성분 갯수 2개 생성\n",
        "principalComponents=pca.fit_transform(x)\n",
        "principal_df=pd.DataFrame(data=principalComponents, columns=['pc1', 'pd2'])\n",
        "principal_df.head()\n",
        "sns.scatterplot(x='pc1', y='pc2', hue=df.Class, data=principal_df) #주성분 산포도\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "esK0qG5Bf-G2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "undersample=RandomUnderSampler(sampling_strategy='majority')\n",
        "oversample=RandomOverSampler(sampling_strategy=0.5)\n",
        "smote_sample=SMOTE(sampling_strategy='minority')\n",
        "x_under, y_under=undersample.fit_resample(x, y)\n",
        "x_over, y_over=oversample.fit_resample(x, y)\n",
        "x_sm, y_sm=smote_sample.fit_resample(x, y)\n",
        "\n",
        "fig, axes=plt.subplots(nrows=2, ncols=2, figsize=(10,10))\n",
        "sns.scatterplot(x[:,1], x[:,2], hue=y, ax=axes[0][0], alpha=0.5)\n",
        "sns.scatterplot(x_under)[:,1], x_under[:,2], hue=y_under, ax=axes[0][1], alpha=0.5)\n",
        "sns.scatterplot(x_over[:,1], x_over[:,2], hue=y_over, ax=axes[1][0], alpha=0.5)\n",
        "sns.scatterplot(x_sm[:,1], x_sm[:,2], hue=y_sm, ax=axes[1][1], alpha=0.5)\n",
        "axes[0][0].set_title('Original Data')\n",
        "axes[0][1].set_title('Random Under Sampling')\n",
        "axes[1][1].set_title('SMOTE')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t_zA2gUnlfXb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}